{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expansión en serie de Taylor:\n",
    "\n",
    "$$\n",
    "f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2!}h^2 + \\frac{f'''(x)}{3!}h^3 + \\cdots\n",
    "$$\n",
    "\n",
    "# Derivada adelantada:\n",
    "\n",
    "$$\n",
    "\\frac{f(x+h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "# Demostración:\n",
    "\n",
    "$$\n",
    "f(x+h) = f(x) + f'(x)h + \\frac{f''(x)}{2!}h^2 + \\frac{f'''(x)}{3!}h^3 + \\cdots\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x+h) - f(x) = f'(x)h + \\frac{f''(x)}{2!}h^2 + \\frac{f'''(x)}{3!}h^3 + \\cdots\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{f(x+h) - f(x)}{h} = f'(x) + \\frac{f''(x)}{2!}h + \\frac{f'''(x)}{3!}h^2 + \\cdots\n",
    "$$\n",
    "\n",
    "La diferencia entre $\\frac{f(x+h) - f(x)}{h}$ y $f'(x)$ está dada por los términos adicionales en la expansión de Taylor que involucran potencias de $h$. Esos términos se vuelven pequeños a medida que $h$ se hace pequeño.\n",
    "\n",
    "Por lo tanto, para valores pequeños de $h$, la fórmula de la derivada adelantada proporciona una buena aproximación de la derivada de la función en $x$.\n",
    "\n",
    "**Nota:** Los términos restantes son el error de truncamiento, que en este caso es del orden $O(h)$.\n",
    "\n",
    "# Derivada centrada:\n",
    "\n",
    "$$\n",
    "\\frac{f(x+h) - f(x-h)}{2h}\n",
    "$$\n",
    "\n",
    "# Demostración:\n",
    "\n",
    "Mediante la expansión en Taylor tenemos:\n",
    "\n",
    "1. \n",
    "$$\n",
    "f(x+h) = f(x) + h f'(x) + \\frac{h^2}{2!} f''(x) + \\frac{h^3}{3!} f'''(x) + \\cdots \\quad \\text{(i)}\n",
    "$$\n",
    "\n",
    "2.\n",
    "$$\n",
    "f(x-h) = f(x) - h f'(x) + \\frac{h^2}{2!} f''(x) - \\frac{h^3}{3!} f'''(x) + \\cdots \\quad \\text{(ii)}\n",
    "$$\n",
    "\n",
    "Para obtener la derivada centrada, restamos (1) y (2):\n",
    "\n",
    "$$\n",
    "f(x+h) - f(x-h) = 2h f'(x) + \\frac{2h^3}{3!} f'''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Dividiendo ambos lados por $2h$, obtenemos:\n",
    "\n",
    "$$\n",
    "\\frac{f(x+h) - f(x-h)}{2h} = f'(x) + \\frac{h^2}{3!} f'''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Los términos restantes del lado derecho representan el error de truncamiento, que en este caso es de orden $O(h^2)$.\n",
    "\n",
    "# Derivada retrasada:\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{f(x) - f(x-h)}{h}\n",
    "$$\n",
    "\n",
    "# Demostración:\n",
    "\n",
    "Usando la expansión en Taylor para $f(x-h)$:\n",
    "\n",
    "$$\n",
    "f(x-h) = f(x) - h f'(x) + \\frac{h^2}{2!} f''(x) - \\frac{h^3}{3!} f'''(x) + \\cdots \\quad \\text{(iii)}\n",
    "$$\n",
    "\n",
    "Restando a (iii) $f(x)$:\n",
    "\n",
    "$$\n",
    "f(x) - f(x-h) = h f'(x) - \\frac{h^2}{2!} f''(x) + \\frac{h^3}{3!} f'''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Dividiendo ambos lados por $h$:\n",
    "\n",
    "$$\n",
    "\\frac{f(x) - f(x-h)}{h} = f'(x) - \\frac{h}{2!} f''(x) + \\frac{h^2}{3!} f'''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Finalmente, obtenemos:\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{f(x) - f(x-h)}{h} + \\frac{h}{2!} f''(x) - \\frac{h^2}{3!} f'''(x) + \\cdots\n",
    "$$\n",
    "\n",
    "Dado que el error de truncamiento será del orden $O(h)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 1:\n",
    "\n",
    "Tomemos $\\hat{a} = a(1 + \\epsilon)$, donde $\\hat{a}$ es el valor de $a$ en el computador, pero con un error de redondeo $\\epsilon$, donde $\\epsilon$ puede depender de $a$.\n",
    "\n",
    "En particular, para la derivada centrada, al evaluar $f(x+h)$ y $f(x-h)$, el computador redondea el resultado como:\n",
    "\n",
    "$$\n",
    "\\hat{f}(x+h) = f(x+h)(1 + \\epsilon_1), \\quad \\hat{f}(x-h) = f(x-h)(1 + \\epsilon_2) \\quad \\text{(1)}\n",
    "$$\n",
    "\n",
    "Y obtenemos que la derivada centrada está dada por:\n",
    "\n",
    "$$\n",
    "\\hat{f}'(x) = \\frac{\\hat{f}(x+h) - \\hat{f}(x-h)}{2h} - f''(\\xi) \\frac{h^2}{3!} \\quad \\text{(2)}\n",
    "$$\n",
    "\n",
    "Reescribiendo la ecuación (2):\n",
    "\n",
    "$$\n",
    "\\hat{f}'(x) - \\left(\\frac{f(x+h) - f(x-h)}{2h}\\right) = -f'''(\\xi) \\frac{h^2}{3!}\n",
    "$$\n",
    "\n",
    "Incorporando el error de redondeo:\n",
    "\n",
    "$$\n",
    "\\hat{f}'(x) - \\frac{f(x+h)(1 + \\epsilon_1) - f(x-h)(1 + \\epsilon_2)}{2h} = -f'''(\\xi) \\frac{h^2}{3!} \n",
    "$$\n",
    "\n",
    "Expandiendo:\n",
    "\n",
    "$$\n",
    "\\hat{f}'(x) - \\frac{f(x+h) - f(x-h)}{2h}  = -f'''(\\xi) \\frac{h^2}{3!} + \\frac{f(x+h)\\epsilon_1 - f(x-h)\\epsilon_2}{2h}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left|\\hat{f}'(x) - \\frac{f(x+h) - f(x-h)}{2h}\\right| = \\left| -f'''(\\xi) \\frac{h^2}{3!} + \\frac{f(x+h)\\epsilon_1 - f(x-h)\\epsilon_2}{2h} \\right|\n",
    "$$\n",
    "\n",
    "Usando la desigualdad triangular:\n",
    "\n",
    "$$\n",
    "\\left|\\hat{f}'(x) - \\frac{f(x+h) - f(x-h)}{2h}\\right| \\leq \\frac{h^2}{3!} \\left|f'''(\\xi)\\right| + \\frac{\\epsilon_1}{2h} \\left|f(x+h)\\right| + \\frac{\\epsilon_2}{2h} \\left|f(x-h)\\right|\n",
    "$$\n",
    "\n",
    "Podemos asumir que:\n",
    "\n",
    "1. Existe un valor $\\epsilon^*$ tal que $\\epsilon_1 \\approx \\epsilon^*$ y $\\epsilon_2 \\approx \\epsilon^*$.\n",
    "2. Si $h \\ll 1$, entonces $\\epsilon \\approx x \\wedge \\left|f(x+h)\\right| \\approx \\left|f(x)\\right|$.\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\left|\\hat{f}'(x) - \\frac{f(x+h) - f(x-h)}{2h}\\right| \\leq \\frac{h^2}{3!} \\left|f'''(x)\\right| + \\frac{\\epsilon^*}{2h} \\left|f(x)\\right| + \\frac{\\epsilon^*}{2h} \\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left|\\hat{f}'(x) - \\frac{f(x+h) - f(x-h)}{2h}\\right| \\leq \\frac{h^2}{3!} \\left|f'''(x)\\right| + \\frac{\\epsilon^*}{h} \\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "De aquí el error absoluto (analítico) es:\n",
    "\n",
    "$$\n",
    "E_{\\text{abs}} = \\frac{h^2}{6} \\left|f'''(x)\\right| + \\frac{\\epsilon^*}{h} \\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "E'_{\\text{abs}} = \\frac{h}{3} \\left|f'''(x)\\right| - \\frac{\\epsilon^*}{h^2} \\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "Y, el error numérico es:\n",
    "\n",
    "$$\n",
    "E_{\\text{num}} = \\left| f'_{\\text{num}}(x) - f'_{\\text{num}}(x) \\right|\n",
    "$$\n",
    "\n",
    "Una buena estimación del error es asumir que $\\epsilon^* \\approx 2^{-\\rho}$, con $2^{-\\rho}$ precisión de máquina ($\\rho = 23$ precisión simple y $\\rho = 52$ precisión doble).\n",
    "\n",
    "Por otro lado, el valor óptimo de $h$ se obtiene a partir de $E'_{\\text{abs}} = 0$. Calculemos:\n",
    "\n",
    "$$\n",
    "\\frac{h}{3} \\left|f'''(x)\\right| = \\frac{\\epsilon^*}{h^2} \\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "$$\n",
    "h^3 = \\frac{3 \\epsilon^* \\left|f(x)\\right|}{\\left|f'''(x)\\right|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "h = \\sqrt[3]{\\frac{3 \\epsilon^* \\left|f(x)\\right|}{\\left|f'''(x)\\right|}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2:\n",
    "\n",
    "Tomamos $\\hat{a} = a(1 + \\epsilon)$, donde $\\hat{a}$ es el valor de $a$ en el computador, pero con error de redondeo $\\epsilon$, donde $\\epsilon$ puede depender de $a$. Para la derivada adelantada, tomamos lo siguiente:\n",
    "\n",
    "$$\n",
    "\\hat{f}(x+h) = f(x+h)(1 + \\epsilon_1)\n",
    "$$\n",
    "\n",
    "Y sabemos que:\n",
    "\n",
    "$$\n",
    "\\frac{f(x+h) - f(x)}{h} = f'(x) + \\frac{f''(x)}{2!}h\n",
    "$$\n",
    "\n",
    "Por lo que:\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{f(x+h) - f(x)}{h} = - \\frac{f''(x)}{2!}h\n",
    "$$\n",
    "\n",
    "Expandiendo:\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{f(x+h)(1+\\epsilon_1) - f(x)(1+\\epsilon_2)}{h}= - \\frac{f''(x)}{2!}h\n",
    "$$\n",
    "\n",
    "Reorganizando:\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{f(x+h) - f(x)}{h} = \\frac{f(x+h)\\epsilon_1 - f(x)\\epsilon_2}{h} - \\frac{f''(x)}{2!}h\n",
    "$$\n",
    "\n",
    "Aplicando la desigualdad triangular:\n",
    "\n",
    "$$\n",
    "\\left|\\hat{f}'(x) - \\frac{f(x+h) - f(x)}{h}\\right| \\leq \\frac{\\epsilon_1}{h} \\left|f(x+h)\\right| + \\frac{\\epsilon_2}{h} \\left|f(x)\\right| + \\frac{h}{2} \\left|f''(x)\\right|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos asumir que:\n",
    "\n",
    "1. Existe un valor $\\epsilon^*$ tal que $\\epsilon_1 \\approx \\epsilon^*$ y $\\epsilon_2 \\approx \\epsilon^*$.\n",
    "2. Si $h \\ll 1$, entonces $\\epsilon \\approx x \\wedge \\left|f(x+h)\\right| \\approx \\left|f(x)\\right|$.\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\left|\\frac{f(x) - f(x+h) + f(x)}{h}\\right| \\leq \\frac{\\epsilon_1}{h} \\left|f(x)\\right| + \\frac{\\epsilon_2}{h} \\left|f(x)\\right| + \\frac{h}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "Simplificando:\n",
    "\n",
    "$$\n",
    "\\left|\\frac{f(x) - f(x+h) + f(x)}{h}\\right| \\leq \\frac{2\\epsilon^*}{h} \\left|f(x)\\right| + \\frac{h}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "De aquí, el error absoluto (analítico) es:\n",
    "\n",
    "$$\n",
    "E_{\\text{abs}} = \\frac{2\\epsilon^*}{h} \\left|f(x)\\right| + \\frac{h}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "El error absoluto derivado es:\n",
    "\n",
    "$$\n",
    "E'_{\\text{abs}} = -\\frac{2\\epsilon^*}{h^2} \\left|f(x)\\right| + \\frac{1}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "Por otro lado, el valor óptimo de $h$ se obtiene a partir de $E'_{\\text{abs}} = 0$. Calculemos:\n",
    "\n",
    "$$\n",
    "-\\frac{2\\epsilon^*}{h^2} \\left|f(x)\\right| + \\frac{1}{2} \\left|f''(x)\\right| = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{4\\epsilon^* \\left|f(x)\\right|}{\\left|f''(x)\\right|} = h^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "h = \\sqrt{\\frac{4\\epsilon^* \\left|f(x)\\right|}{\\left|f''(x)\\right|}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 3:\n",
    "\n",
    "Tomamos $\\hat{a} = a(1 + \\epsilon)$, donde $\\hat{a}$ es el valor de $a$ en el computador, pero con error de redondeo $\\epsilon$, donde $\\epsilon$ puede depender de $a$. Para la derivada retrasada, tomamos lo siguiente:\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{f(x) - f(x-h)}{h} + \\frac{h}{2!}f''(x)\n",
    "$$\n",
    "\n",
    "donde, como mencionamos, hemos redondeado\n",
    "\n",
    "$$\n",
    "\\hat{f}(x-h) = f(x-h)(1 + \\epsilon_2) \\quad \\text{y} \\quad \\hat{f}(x) = f(x)(1 + \\epsilon_1)\n",
    "$$\n",
    "\n",
    "Realicemos el análisis:\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{\\hat{f}(x) - \\hat{f}(x-h)}{h} = \\frac{h}{2!} f''(x)\n",
    "$$\n",
    "\n",
    "Expandiendo y simplificando:\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{f(x)(1 + \\epsilon_1) - f(x-h)(1 + \\epsilon_2)}{h} = \\frac{h}{2!} f''(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f'(x) - \\frac{f(x) - f(x-h)}{h} = \\frac{h}{2!} f''(x) + \\frac{f(x)\\epsilon_1 - f(x-h)\\epsilon_2}{h}\n",
    "$$\n",
    "\n",
    "Aplicando la desigualdad triangular:\n",
    "\n",
    "$$\n",
    "\\left|f'(x) - \\frac{f(x) - f(x-h)}{h}\\right| \\leq \\frac{h}{2} \\left|f''(x)\\right| + \\frac{\\epsilon_1}{h} \\left|f(x)\\right| + \\frac{\\epsilon_2}{h} \\left|f(x-h)\\right|\n",
    "$$\n",
    "\n",
    "Podemos asumir que:\n",
    "\n",
    "1. Existe un valor $\\epsilon^*$ tal que $\\epsilon_1 \\approx \\epsilon^*$ y $\\epsilon_2 \\approx \\epsilon^*$.\n",
    "2. Si $h \\ll 1$, entonces $\\epsilon \\approx x \\wedge \\left|f(x+h)\\right| \\approx \\left|f(x)\\right|$.\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\left|f'(x) - \\frac{f(x) - f(x-h)}{h}\\right| \\leq \\frac{h}{2} \\left|f''(x)\\right| + \\frac{2 \\epsilon^*}{h^2}\\left|f(x)\\right|\n",
    "$$\n",
    "\n",
    "De aquí, el error absoluto (analítico) es:\n",
    "\n",
    "$$\n",
    "E_{\\text{abs}} = \\frac{2\\epsilon^*}{h} \\left|f(x)\\right| + \\frac{h}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "El error absoluto derivado es:\n",
    "\n",
    "$$\n",
    "E'_{\\text{abs}} = -\\frac{2\\epsilon^*}{h^2} \\left|f(x)\\right| + \\frac{1}{2} \\left|f''(x)\\right|\n",
    "$$\n",
    "\n",
    "Por otro lado, el valor óptimo de $h$ se obtiene a partir de $E'_{\\text{abs}} = 0$. Calculemos:\n",
    "\n",
    "$$\n",
    "-\\frac{2\\epsilon^*}{h^2} \\left|f(x)\\right| + \\frac{1}{2} \\left|f''(x)\\right| = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{4\\epsilon^* \\left|f(x)\\right|}{\\left|f''(x)\\right|} = h^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "h = \\sqrt{\\frac{4\\epsilon^* \\left|f(x)\\right|}{\\left|f''(x)\\right|}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio: Análisis del Efecto del Ruido en la Derivación Numérica\n",
    "\n",
    "**Objetivo:** Este ejercicio tiene como objetivo explorar el impacto del ruido en los datos sobre la precisión de las derivadas numéricas, utilizando los métodos de derivada adelantada, retrasada y centrada. Además, se busca que el estudiante comprenda cómo el ruido puede afectar el procesamiento de datos experimentales en física.\n",
    "\n",
    "## Parte 1: Derivación de una Función con Ruido\n",
    "\n",
    "1. **Instrucciones:**\n",
    "   - Considera la función $f(x) = \\sin(x)$.\n",
    "   - Genera una versión \"ruidosa\" de la función $f(x)$, añadiendo un pequeño ruido aleatorio a los valores de $f(x)$.\n",
    "   - Calcula las derivadas numéricas de la función con ruido utilizando los tres métodos de derivación: adelantada, retrasada y centrada.\n",
    "   - Compara los resultados obtenidos con la derivada exacta $f'(x) = \\cos(x)$.\n",
    "   - Grafica las derivadas numéricas junto con la derivada exacta y analiza los efectos del ruido.\n",
    "\n",
    "2. **Preguntas:**\n",
    "   - ¿Cómo afecta el ruido en los datos a la precisión de cada método de derivación numérica?\n",
    "   - ¿Cuál de los métodos es más robusto frente al ruido y por qué?\n",
    "   - Modifique en valor de h y argumente que sucede con las derivadas numéricas\n",
    "\n",
    "## Parte 2: Generación de Ruido en los Datos (Ayuda)\n",
    "\n",
    "Para añadir ruido a los datos de una función, puedes utilizar la función `np.random.randn()` de la librería `numpy`, que genera números aleatorios siguiendo una distribución normal (media 0 y desviación estándar 1). Estos valores se pueden escalar mediante un parámetro de nivel de ruido para controlar la intensidad del ruido añadido. A continuación se muestra un ejemplo de cómo hacerlo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función original\n",
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "# Generar ruido en los datos\n",
    "def f_with_noise(x, noise_level=0.01):\n",
    "    # Genera ruido aleatorio con una amplitud controlada por noise_level\n",
    "    noise = noise_level * np.random.randn(*x.shape)\n",
    "    # Añade el ruido a la función original\n",
    "    return f(x) + noise\n",
    "\n",
    "# Ejemplo de uso\n",
    "x = np.linspace(0, 2 * np.pi, 100)\n",
    "f_noisy = f_with_noise(x, noise_level=0.02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicación:\n",
    "\n",
    "- `noise_level`: Controla la amplitud del ruido. Un valor más alto de `noise_level` genera datos más \"ruidosos\".\n",
    "- `np.random.randn(*x.shape)`: Genera un array de números aleatorios con la misma forma que `x`. Estos valores se multiplican por `noise_level` para ajustar la intensidad del ruido.\n",
    "- `f_with_noise(x)`: Devuelve la función $\\sin(x)$ con ruido añadido.\n",
    "\n",
    "Utiliza esta función `f_with_noise(x)` para crear la función ruidosa que luego derivarás utilizando los métodos numéricos. Recuerda que el ruido puede simularse como una perturbación aleatoria en datos experimentales reales, como los que podrías encontrar en mediciones físicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Comparación de Métodos para Diferentes Funciones\n",
    "\n",
    "**Objetivo:** Comparar la precisión de los métodos de derivación numérica para diferentes tipos de funciones.\n",
    "\n",
    "1. **Instrucciones:**\n",
    "   - Implementa las siguientes funciones: $f(x) = \\sin(x)$, $f(x) = e^x$, $f(x) = \\ln(x)$ (en $x > 0$), y $f(x) = x^2$.\n",
    "   - Calcula las derivadas numéricas usando los tres métodos para cada función.\n",
    "   - Grafica todas las derivadas y compara con las derivadas exactas de cada función.\n",
    "\n",
    "2. **Preguntas:**\n",
    "   - ¿Qué función resulta más difícil de derivar numéricamente?\n",
    "   - ¿Qué observaciones puedes hacer acerca de la precisión de cada método en función del tipo de función?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
